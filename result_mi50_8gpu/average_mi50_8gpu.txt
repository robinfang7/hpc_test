benchmark start : 2021/02/02 09:50:18
Number of GPUs on current device : 8
CUDA Version : None
Cudnn Version : 2009000
Device Name : Device 66a1
uname_result(system='Linux', node='aa591c33a553', release='5.4.0-60-generic', version='#67~18.04.1-Ubuntu SMP Tue Jan 5 22:01:05 UTC 2021', machine='x86_64', processor='x86_64')
                     scpufreq(current=2798.7736875000005, min=1500.0, max=2250.0)
                    cpu_count: 128
                    memory_available: 533508411392
Benchmarking Training float precision type resnet18
libibverbs: Warning: couldn't open config directory '/etc/libibverbs.d'.
resnet18 model average train time : 38.71834754943848ms
Benchmarking Training float precision type resnet34
resnet34 model average train time : 65.40886402130127ms
Benchmarking Training float precision type resnet50
resnet50 model average train time : 90.67001819610596ms
Benchmarking Training float precision type resnet101
resnet101 model average train time : 168.74528408050537ms
Benchmarking Training float precision type resnet152
resnet152 model average train time : 250.24603843688965ms
Benchmarking Training float precision type resnext50_32x4d
resnext50_32x4d model average train time : 89.93955135345459ms
Benchmarking Training float precision type resnext101_32x8d
resnext101_32x8d model average train time : 181.20169162750244ms
Benchmarking Training float precision type wide_resnet50_2
wide_resnet50_2 model average train time : 102.17127323150635ms
Benchmarking Training float precision type wide_resnet101_2
wide_resnet101_2 model average train time : 192.56545066833496ms
Benchmarking Inference float precision type resnet18
resnet18 model average inference time : 23.406648635864258ms
Benchmarking Inference float precision type resnet34
resnet34 model average inference time : 38.602728843688965ms
Benchmarking Inference float precision type resnet50
resnet50 model average inference time : 52.28545665740967ms
Benchmarking Inference float precision type resnet101
resnet101 model average inference time : 98.06352138519287ms
Benchmarking Inference float precision type resnet152
resnet152 model average inference time : 143.76539707183838ms
Benchmarking Inference float precision type resnext50_32x4d
resnext50_32x4d model average inference time : 51.687865257263184ms
Benchmarking Inference float precision type resnext101_32x8d
resnext101_32x8d model average inference time : 98.29626083374023ms
Benchmarking Inference float precision type wide_resnet50_2
wide_resnet50_2 model average inference time : 55.94147205352783ms
Benchmarking Inference float precision type wide_resnet101_2
wide_resnet101_2 model average inference time : 102.53028869628906ms
Benchmarking Training half precision type resnet18
resnet18 model average train time : 41.77915096282959ms
Benchmarking Training half precision type resnet34
resnet34 model average train time : 72.2900915145874ms
Benchmarking Training half precision type resnet50
resnet50 model average train time : 93.19393634796143ms
Benchmarking Training half precision type resnet101
resnet101 model average train time : 177.67825603485107ms
Benchmarking Training half precision type resnet152
resnet152 model average train time : 264.3718957901001ms
Benchmarking Training half precision type resnext50_32x4d
resnext50_32x4d model average train time : 94.12365913391113ms
Benchmarking Training half precision type resnext101_32x8d
resnext101_32x8d model average train time : 184.88674640655518ms
Benchmarking Training half precision type wide_resnet50_2
wide_resnet50_2 model average train time : 94.02462959289551ms
Benchmarking Training half precision type wide_resnet101_2
wide_resnet101_2 model average train time : 177.50998497009277ms
Benchmarking Inference half precision type resnet18
resnet18 model average inference time : 22.60608673095703ms
Benchmarking Inference half precision type resnet34
resnet34 model average inference time : 41.32887363433838ms
Benchmarking Inference half precision type resnet50
resnet50 model average inference time : 56.35567665100098ms
Benchmarking Inference half precision type resnet101
resnet101 model average inference time : 100.51225185394287ms
Benchmarking Inference half precision type resnet152
resnet152 model average inference time : 153.7641191482544ms
Benchmarking Inference half precision type resnext50_32x4d
resnext50_32x4d model average inference time : 55.311551094055176ms
Benchmarking Inference half precision type resnext101_32x8d
resnext101_32x8d model average inference time : 103.6113691329956ms
Benchmarking Inference half precision type wide_resnet50_2
wide_resnet50_2 model average inference time : 60.7195520401001ms
Benchmarking Inference half precision type wide_resnet101_2
wide_resnet101_2 model average inference time : 104.42120552062988ms
Benchmarking Training double precision type resnet18
resnet18 model average train time : 62.11285591125488ms
Benchmarking Training double precision type resnet34
resnet34 model average train time : 96.88510417938232ms
Benchmarking Training double precision type resnet50
resnet50 model average train time : 123.91908645629883ms
Benchmarking Training double precision type resnet101
resnet101 model average train time : 220.00227451324463ms
Benchmarking Training double precision type resnet152
resnet152 model average train time : 312.6937961578369ms
Benchmarking Training double precision type resnext50_32x4d
resnext50_32x4d model average train time : 425.9660339355469ms
Benchmarking Training double precision type resnext101_32x8d
resnext101_32x8d model average train time : 797.0435237884521ms
Benchmarking Training double precision type wide_resnet50_2
wide_resnet50_2 model average train time : 169.20215129852295ms
Benchmarking Training double precision type wide_resnet101_2
wide_resnet101_2 model average train time : 306.91468238830566ms
Benchmarking Inference double precision type resnet18
resnet18 model average inference time : 36.349616050720215ms
Benchmarking Inference double precision type resnet34
resnet34 model average inference time : 56.10830307006836ms
Benchmarking Inference double precision type resnet50
resnet50 model average inference time : 66.55286312103271ms
Benchmarking Inference double precision type resnet101
resnet101 model average inference time : 111.5200138092041ms
Benchmarking Inference double precision type resnet152
resnet152 model average inference time : 159.6488094329834ms
Benchmarking Inference double precision type resnext50_32x4d
resnext50_32x4d model average inference time : 111.3849925994873ms
Benchmarking Inference double precision type resnext101_32x8d
resnext101_32x8d model average inference time : 251.37460708618164ms
Benchmarking Inference double precision type wide_resnet50_2
wide_resnet50_2 model average inference time : 81.74521446228027ms
Benchmarking Inference double precision type wide_resnet101_2
wide_resnet101_2 model average inference time : 143.20592403411865ms
benchmark end : 2021/02/02 10:03:35
