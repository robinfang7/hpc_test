benchmark start : 2021/02/02 08:56:20
Number of GPUs on current device : 8
CUDA Version : None
Cudnn Version : 2009000
Device Name : Device 66a1
uname_result(system='Linux', node='aa591c33a553', release='5.4.0-60-generic', version='#67~18.04.1-Ubuntu SMP Tue Jan 5 22:01:05 UTC 2021', machine='x86_64', processor='x86_64')
                     scpufreq(current=2929.3164375000006, min=1500.0, max=2250.0)
                    cpu_count: 128
                    memory_available: 533639823360
Benchmarking Training float precision type resnet18
libibverbs: Warning: couldn't open config directory '/etc/libibverbs.d'.
resnet18 model average train time : 25.79054355621338ms
Benchmarking Training float precision type resnet34
resnet34 model average train time : 40.935187339782715ms
Benchmarking Training float precision type resnet50
resnet50 model average train time : 61.89718246459961ms
Benchmarking Training float precision type resnet101
resnet101 model average train time : 111.49654865264893ms
Benchmarking Training float precision type resnet152
resnet152 model average train time : 161.83602809906006ms
Benchmarking Training float precision type resnext50_32x4d
resnext50_32x4d model average train time : 64.35359001159668ms
Benchmarking Training float precision type resnext101_32x8d
resnext101_32x8d model average train time : 169.38347339630127ms
Benchmarking Training float precision type wide_resnet50_2
wide_resnet50_2 model average train time : 97.19043731689453ms
Benchmarking Training float precision type wide_resnet101_2
wide_resnet101_2 model average train time : 176.21593952178955ms
Benchmarking Inference float precision type resnet18
resnet18 model average inference time : 11.807112693786621ms
Benchmarking Inference float precision type resnet34
resnet34 model average inference time : 17.48286247253418ms
Benchmarking Inference float precision type resnet50
resnet50 model average inference time : 25.984797477722168ms
Benchmarking Inference float precision type resnet101
resnet101 model average inference time : 44.697346687316895ms
Benchmarking Inference float precision type resnet152
resnet152 model average inference time : 63.93463611602783ms
Benchmarking Inference float precision type resnext50_32x4d
resnext50_32x4d model average inference time : 27.599081993103027ms
Benchmarking Inference float precision type resnext101_32x8d
resnext101_32x8d model average inference time : 63.488759994506836ms
Benchmarking Inference float precision type wide_resnet50_2
wide_resnet50_2 model average inference time : 36.788249015808105ms
Benchmarking Inference float precision type wide_resnet101_2
wide_resnet101_2 model average inference time : 64.69689846038818ms
Benchmarking Training half precision type resnet18
resnet18 model average train time : 26.737875938415527ms
Benchmarking Training half precision type resnet34
resnet34 model average train time : 41.95235252380371ms
Benchmarking Training half precision type resnet50
resnet50 model average train time : 62.46345043182373ms
Benchmarking Training half precision type resnet101
resnet101 model average train time : 107.53131866455078ms
Benchmarking Training half precision type resnet152
resnet152 model average train time : 157.17424869537354ms
Benchmarking Training half precision type resnext50_32x4d
resnext50_32x4d model average train time : 64.42801475524902ms
Benchmarking Training half precision type resnext101_32x8d
resnext101_32x8d model average train time : 164.41072940826416ms
Benchmarking Training half precision type wide_resnet50_2
wide_resnet50_2 model average train time : 90.20578384399414ms
Benchmarking Training half precision type wide_resnet101_2
wide_resnet101_2 model average train time : 149.64828968048096ms
Benchmarking Inference half precision type resnet18
resnet18 model average inference time : 10.749096870422363ms
Benchmarking Inference half precision type resnet34
resnet34 model average inference time : 16.613821983337402ms
Benchmarking Inference half precision type resnet50
resnet50 model average inference time : 29.99053955078125ms
Benchmarking Inference half precision type resnet101
resnet101 model average inference time : 48.50738525390625ms
Benchmarking Inference half precision type resnet152
resnet152 model average inference time : 74.89409923553467ms
Benchmarking Inference half precision type resnext50_32x4d
resnext50_32x4d model average inference time : 31.91025733947754ms
Benchmarking Inference half precision type resnext101_32x8d
resnext101_32x8d model average inference time : 68.17892074584961ms
Benchmarking Inference half precision type wide_resnet50_2
wide_resnet50_2 model average inference time : 34.83166217803955ms
Benchmarking Inference half precision type wide_resnet101_2
wide_resnet101_2 model average inference time : 57.236976623535156ms
Benchmarking Training double precision type resnet18
resnet18 model average train time : 93.93652439117432ms
Benchmarking Training double precision type resnet34
resnet34 model average train time : 157.79332160949707ms
Benchmarking Training double precision type resnet50
resnet50 model average train time : 205.05019664764404ms
Benchmarking Training double precision type resnet101
resnet101 model average train time : 342.42708683013916ms
Benchmarking Training double precision type resnet152
resnet152 model average train time : 479.17726039886475ms
Benchmarking Training double precision type resnext50_32x4d
resnext50_32x4d model average train time : 855.6925106048584ms
Benchmarking Training double precision type resnext101_32x8d
resnext101_32x8d model average train time : 1677.3231887817383ms
Benchmarking Training double precision type wide_resnet50_2
wide_resnet50_2 model average train time : 339.7339630126953ms
Benchmarking Training double precision type wide_resnet101_2
wide_resnet101_2 model average train time : 615.5566453933716ms
Benchmarking Inference double precision type resnet18
resnet18 model average inference time : 43.43085289001465ms
Benchmarking Inference double precision type resnet34
resnet34 model average inference time : 76.03259563446045ms
Benchmarking Inference double precision type resnet50
resnet50 model average inference time : 84.3032455444336ms
Benchmarking Inference double precision type resnet101
resnet101 model average inference time : 148.03279399871826ms
Benchmarking Inference double precision type resnet152
resnet152 model average inference time : 211.94751739501953ms
Benchmarking Inference double precision type resnext50_32x4d
resnext50_32x4d model average inference time : 197.7063226699829ms
Benchmarking Inference double precision type resnext101_32x8d
resnext101_32x8d model average inference time : 528.8998126983643ms
Benchmarking Inference double precision type wide_resnet50_2
wide_resnet50_2 model average inference time : 148.3712911605835ms
Benchmarking Inference double precision type wide_resnet101_2
wide_resnet101_2 model average inference time : 269.2217540740967ms
benchmark end : 2021/02/02 09:15:50

